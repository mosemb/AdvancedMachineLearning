{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphical lasso\n",
    "\n",
    "The graphical lasso is a method proposed by Friedman et al. in 2007 to estimate a sparse graph through a sparse penalty.\n",
    "\n",
    "\n",
    "This models assumes that the covariates we are analyzing have a multivariate Gaussian distribution with mean $\\mu$ and covariance $\\Sigma$.\n",
    "\n",
    "Moreover it is known that if the $ij$-th components of the inverse of the covariance matrix $\\Sigma^{-1} = \\Theta$ is zero, than the two variables $i$ and $j$ are conditionally independent given the others variable.\n",
    "\n",
    "Some papers proposed different methods to reach an approximate solution of the problem, typically they are based on the maximization of a likelihood, derived from the distribution, given as \n",
    "\n",
    "$$ \\text{log det}\\Theta - \\text{tr}(S\\Theta) $$\n",
    "\n",
    "where $\\Theta$ is the inverse of the covariance matrix and its the unknown graph we want to estimate, and $S$ is the empirical covariance of our data. \n",
    "If we have a matrix $X \\in \\mathcal{R}^{n \\times d}$ than $S=\\frac{1}{n}X^TX \\in \\mathcal{R}^{d \\times d}$\n",
    "\n",
    "Since the $\\Theta$ is supposed to be sparse the final functional imposes also a sparse penalty on it.\n",
    "\n",
    "$$ \\hat{\\Theta} = \\underset{\\Theta}{\\text{argmin}}\\left(\\text{tr}(S\\Theta) - \\text{log det}(\\Theta) + \\lambda\\sum_{j\\neq k}|\\Theta_{jk}|\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this lab you are going infer a sparse network in two flavors:\n",
    "    \n",
    "    -Supervised\n",
    "    -Unsupervised\n",
    "    \n",
    "**More specifically, you will be given n observations, drawn from a fully specified multivariate Gaussian distribution, whose precision matrix is known. You will infer a precision matrix by maximizing a score in a cross-validation scheme (supervised) and then you will assume you do not know the underlying distribution (*i.e.* the precision matrix) and will try to infer a precision matrix in an unsupervised manner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the distribution, the number of samples, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The precision matrix is the following `precision`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = np.load('precision.npy')\n",
    "\n",
    "plt.imshow(precision, cmap = 'viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You are going to use the sklearn [GraphLasso](https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLasso.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a plausible list of parameters for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each hyper-parameter in the list `alphas` fit a GraphicaLasso model to your data and choose the best one according to score of your choice (**Hint: remember that inferring the right edges is equivalent to inferring the right class in a binary classificaion problem**). For stability analysis, you could also try the same setting for different splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import GraphicalLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function able to recover the corresponding adjacency matrix from an arbitrary square matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the aground-truth adjacency matrix with the inferred one usign the **Hamming distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning of the precision matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that you do not know the precision matrix of the underlying data distribution. You need to perform inference of the precision matrix only using your observations. Typically, in this setting, Probabilistic model selection (or “information criteria”) provides an analytical technique for scoring and choosing among candidate models.\n",
    "\n",
    "You are going to use the **`Bayesian Information Criterion (BIC)`**, appropriate for models fit under the maximum likelihood estimation framework.\n",
    "\n",
    "It is defined as:\n",
    "\n",
    "$$BIC = -2LL + \\log(N)k$$\n",
    "\n",
    "where LL is the log-likelihood of the model, N is the number of examples in the training dataset, and k is the number of parameters in the model.\n",
    "\n",
    "The score as defined above is minimized, e.g. the model with the lowest BIC is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function for computing the BIC specific for the Graphical Lasso likelihood:**\n",
    "\n",
    "$$ \\text{log det}\\Theta - \\text{tr}(S\\Theta) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a splitting scheme in order to obtain for each split the BIC and for each hyper-parameter an average BIC over the splits. Then plot the average BIC against the parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After selecting the parameter which minimizes the BIC, compares the inferred network with the ground truth in terms of Hamming distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
