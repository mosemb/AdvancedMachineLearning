{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene co-expression network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gene co-expression network (GCN) is an undirected graph, where each node corresponds to a gene, and a pair of nodes is connected with an edge if there is a significant co-expression relationship between them.\n",
    "\n",
    "In this context we want to link only those genes that are directly dependent from one another and not linked through a third gene. \n",
    "\n",
    "In the state of the art you may find several methods for the inference of graphs based on different concepts. Today we are going to see **Algorithm for the Reconstruction of Accurate Cellular Networks** (ARACNe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "Load the files we used last lab `\"gedm.csv\"` and `\"labels.csv\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gedm.csv\", index_col=0)\n",
    "labels = pd.read_csv(\"labels.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows that start with AFFX and select a sub-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.index[data.index.str.startswith('AFFX')], inplace=True)\n",
    "X = data.iloc[np.random.randint(0, data.shape[0], 30), :].values.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARACNe\n",
    "\n",
    "https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-S1-S7\n",
    "\n",
    "It is a method for the reverse engineering of transcriptional networks. It defines an edge between two gene expression profiles as an *irreducible statistical dependency* that cannot be explained as an artifact or other statistical dependencies in the network.\n",
    "\n",
    "The joint probability distribution over the genes is defined as \n",
    "<img src=\"jpd.png\"/>\n",
    "where $Z$ is a normalization factor, $N$ is the number of genes and $\\Phi$ are the potentials. In the model we say that two variables interact iff their potential is nonzero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimation of the network is done through 3 main steps:\n",
    "\n",
    "    1) computation of pairwise mutual information\n",
    "    2) statistical threshold for mutual information\n",
    "    3) data processing inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of pairwise mutual information\n",
    "The mutual information $I(g_i, g_j) = I_{ij}$ is an information-theoretic measure of relatedness that is zero iff $P(g_i, g_j) = P(g_i)P(g_j)$ i.e., if the genes $g_i$ and $g_j$ are independent. \n",
    "\n",
    "The mutual information is defined, for a pair of random variables $x$ and $y$ as $I(x,y) = S(x) + S(y) - S(x,y)$ where $S(t)$ is the *entropy*.\n",
    "\n",
    "The entropy of a random variable t is defined as: \n",
    "\n",
    "\n",
    "<center>$\\Large{S(t) = - \\mathbb{E}[\\text{log}p(t)] = - \\sum\\limits_{i}p(t_i)\\text{log}(p(t_i))}$</center>\n",
    "\n",
    "with $p(t_i)$ is the probability of each discrete state of the variable.\n",
    "\n",
    "Therefore\n",
    "<center>$\\Large{I(g_i,g_j)=I_{ij}=\\sum\\limits_{h,k}p(g_{ih},g_{jk})log\\bigg{[}\\frac{p(g_{ih},g_{jk})}{p(g_ih)p(g_jk)}\\bigg{]}}$</center>.\n",
    "\n",
    "This measure can be generalized to the continuous case easily. \n",
    "Mutual information is guaranteed to be nonzero iff any kind of statistical dependence exists. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above definitions are well defined for discrete data and probability mass functions. When dealing with **continuous random variables** (as *microarray data*) we need to realiably estimate the density function from data in order to be able to compute the mutual information between each pair of genes.\n",
    "\n",
    "**Kernel Density Estimation (KDE)** is a nonparametric method for estimating probability densities.\n",
    "\n",
    "We can approximate the underlying density of our data by computing,\n",
    "\n",
    "<center>$\\Large{\\hat{p}(x)=\\frac{1}{n}\\sum\\limits_{i}^H\\mathbf{K}(u)}$,</center>\n",
    "\n",
    "where $\\large{u=\\frac{(x-x_i)^TS^{-1}(x-x_i)}{h^2}}$, $\\mathbf{K}(u)$ is a multivariate kernel function, $x=[x_1,\\dots,x_d]^T$ is the $d$-dimensional random vector whose density is being estimated, $x_i=[x_{i1},\\dots,x_{in}]^T$ with $i=1,\\dots,n$ are the n sample vectors, $h$ is the kernel bandwidth, $S$ is the covarinace matrix of the observations $x_i$ and $H$ prescribes the range of data over which the average is computed.\n",
    "\n",
    "We use the multivariate Gaussian probability density function for the kernel function $\\mathbf{K}(u)$ which is given by \n",
    "\n",
    "\n",
    "<center>$\\large{\\mathbf{K}(u)=\\frac{1}{(2\\pi)^{\\frac{d}{2}}h^d det(S)^{\\frac{1}{2}}}exp(-\\frac{u}{2})}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In `utils.py` you may find already defined functions for the kernel density estimation of the joint probability denisty function (`p_mkde_M`), the marginals (`p_kde`) and for the approximation of mutual information using kernel estimations (`kernel_mi`).**\n",
    "\n",
    "**Use these functions to compute the $N_{genes}\\times N_{genes}$ mutual information matrix (MI) from your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import kernel_mi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e6776814eda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mMI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mMI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mutual_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e6776814eda5>\u001b[0m in \u001b[0;36mcompute_mutual_information\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mutual_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Insert your code here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mutual_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MI' is not defined"
     ]
    }
   ],
   "source": [
    "def compute_mutual_information(X):\n",
    "    #Insert your code here\n",
    "    return MI\n",
    "\n",
    "MI = compute_mutual_information(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Gene expressions and the mutual information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 13))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(X,interpolation='None')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title('Gene expression')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(MI,interpolation='None')\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title('Mutual Information between gene pairs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical threshold for mutual information\n",
    "\n",
    "Since MI is always non-negative its evaluation gives positive values even for variables that are mutually independent. Therefore we need to eliminate those edges for which there is no evidence against the hypothesis of mutual independence (the null hypothesis).\n",
    "\n",
    "We want to obtain a statistical threshold $I_0$ on computed mutual informations able to identify those connections that do not actually exist.\n",
    "To this extent, fixed a p-value, consider a set of genes and a **bilateral statistical test** of samples independence.\n",
    "\n",
    "We use as test statistic the mutual information between pairs of genes. In order to compute the p-value we should know the distribution of mutual informations under the null-hypothesis, since the p-value is defined as\n",
    "\n",
    "<center>$\\large{p_{H_0}(I>=I_0)}$.</center>\n",
    "\n",
    "Nevertheless, we do not know the distribution of mutual information on independent variables. We need to perform **Monte Carlo** simulations on independent data in order to obtain an approximate distribution of MIs. We do this by shuffling the genes across the profiles and evaluate the MI of these manifestly independent genes.\n",
    "\n",
    "\n",
    "We then compute the threshold based on our confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the distribution of observed mutual informations on our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = np.ndarray.flatten(MI)\n",
    "idxx = np.where(aux != 0)\n",
    "MI_list = np.ndarray.tolist(aux[idxx])\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bins = np.linspace(min(MI_list), max(MI_list), 101)\n",
    "plt.hist(MI_list, bins, facecolor='b',alpha=0.75)\n",
    "plt.xlabel('Mutual Information')\n",
    "plt.ylabel('Count of associations')\n",
    "plt.title('Distribution of observed Mutual Information');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill the function below aimed to compute the mutual information on different permutations of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutated_MI(X, N_perm):\n",
    "    \n",
    "    #Insert your code here\n",
    "        \n",
    "    return MI_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_perm = permutated_MI(X, N_perm=1) \n",
    "MI_perm = np.ndarray.flatten(MI_perm)\n",
    "idx = np.where(MI_perm != 0)\n",
    "MI_list2 = np.ndarray.tolist(MI_perm[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the data empirical distribution together with the approximated empirical distribution of independent samples. What can you observe?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(MI_list, bins,facecolor='b', alpha=0.75,label='original data')\n",
    "plt.hist(MI_list2, bins,facecolor='g', alpha=0.75,label='shuffled data')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# plt.axvline(np.amax(matMI_alternative),c='r',linewidth=4)\n",
    "plt.xlabel('Mutual Information')\n",
    "plt.ylabel('Count of associations')\n",
    "plt.title('Distribution of calculated Mutual Information');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's compute the empirical complementary cumulative distribution function of the synthetic data\n",
    "and compute the threshold based on a fixed significance level p**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 0.1\n",
    "\n",
    "def eccd(synth_data,data):\n",
    "    #Insert your code here\n",
    "    return emp_eccd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the empirical complememtary cumulative distribution function on data defined below. Is it coherent with what you expected?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = #?\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(data,eccd(MI_perm,data),lw = 2,color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We compute the statistical threshold by looking for the value of the synthetic data for which the probability\n",
    "of observing values greater than that is less or equal than p**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.unique(np.sort(MI_perm))\n",
    "observed_eccd = eccd(MI_perm,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the statistical threshold $I_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Statistical threshold: $I_0$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the data empirical distribution together with the approximated empirical distribution of independent sample and the estimated statistical threshold. What can you obseerve?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.hist(MI_list, bins,facecolor='b', alpha=0.75,label='original data')\n",
    "plt.hist(MI_list2, bins,facecolor='g', alpha=0.75,label='shuffled data')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.axvline(I_0,c='r',linewidth=4)\n",
    "plt.xlabel('Mutual Information')\n",
    "plt.ylabel('Count of associations')\n",
    "plt.title('Distribution of calculated Mutual Information');\n",
    "\n",
    "print('Maximum MI value for the shuffled matrix: {}'.format(np.max(MI_perm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `plt.imshow` to visualize the MI matrix with and without sparsity induced by the threshold** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_filtered = #The mutual information matrix with edges removed cause of the sparisty induced by the statistical threshold\n",
    "\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(13, 13))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing inequality (DPI)\n",
    "\n",
    "We want to exclude those genes that are connected through a third gene. We now that if the genes $g_1$ and $g_3$ are connected through $g_2$ then\n",
    "\n",
    "$I(g_1, g_3) \\leq \\text{min}\\bigg(I(g_1, g_2), I(g_2, g_3)\\bigg)$\n",
    "\n",
    "therefore we look at all the triplets of genes in the resulting matrix of the previous step and we eliminate those edges that respects this inequality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function able to detect the smallest mutual information between a triplets and remove the corresponding edge in the final graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_cycles(MI_filtered):\n",
    "    \n",
    "    return MI_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `plt.imshow` to visualize the MI matrices with and without sparsity induced by the threshold and DPI** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We evaluate the previous pipeline for the inference of regulatory networks from gene expression data comparing the inferred network with a 'syntehtic' one. The synthetic one is obtained by simulating sort of metabolic processes, based on sets of coupled differential equations. To fully define a gene network model it is also necessary to create a network topology, or wiring diagram. Past research in gene networks has concentrated on a particular topological class: random gene networks. These random networks follow a topology studied earlier by mathematicians Erdo ̈s and Re ́nyi, where each vertex of a graph is equally likely to be connected to any other vertex in the graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We obtained a dataset compatible with the above description at the `Artificial Gene Network Series Century`[http://www.comp-sys-bio.org/AGN/Century/]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the gene expression data\n",
    "\n",
    "df = pd.read_csv('CenturyRND.csv',sep='\\t')\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['G'+str(i) for i in range(1,101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the network edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv('CenturyRND-net.csv', sep=' ')\n",
    "edges = pd.DataFrame(edges)\n",
    "edges = edges[['Node1','Node2']]\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's build the network with `networkx` and obtain the adjacency matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "edges_ground_truth = edges.values\n",
    "ground_net = nx.Graph()\n",
    "ground_net.add_nodes_from([i for i in range(1,101) if i not in cols_to_delete])\n",
    "ground_net.add_edges_from(edges_ground_truth)\n",
    "adj_ground_net = nx.adjacency_matrix(ground_net).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,7))\n",
    "nx.draw_circular(ground_net,with_labels=True, node_size=400, node_color='cyan',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(adj_ground_net)\n",
    "plt.title(\"Adjacency matrix of the ground-truth network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use ARACNe method for inferring the network. Refer to the previous pipeline. We have already computed the matrices MI and MI_perm since their computation is pretty expensive. You just need to load them as `np.array`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "MI = load('MI.npy')\n",
    "MI_perm = load('MI_perm.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a function able to recover the undirected network from the inferred mutual information matrix and find a way to compare the obtained adjacency matrix with the ground-truth in order to evaluate the inference result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
