{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyoSlVwcVjJZ"
   },
   "source": [
    "# Lab 6: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIrcn0FIVjJb"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?id=1jUGAOq9z6rLNTq8Y1zHxFF76h5lplwRO\" width=\"600px\" align=\"right\"><br>\n",
    "In this laboratory we continue to work with Keras. We will focus on Convolutional Neural Network\n",
    "we are going to work with a dataset made by approximately five thousand images of different sizes showing plastic shapes -one shape per picture- coming from 10 different classes. <br>\n",
    "<br>\n",
    "The data have been acquired in the development of a lab activity presented at Festival della Scienza 2019 <br>\n",
    "During this laboratory we are going to focus over the shape recognition module by trying to classify single shapes inside the pictures<br>\n",
    "<br>\n",
    "Therefore the main goal of this laboratory is to solve a multiclass classification problem with 10 different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60nvdIK0VjJc"
   },
   "outputs": [],
   "source": [
    "# Download the dataset in Google Drive\n",
    "!wget https://www.dropbox.com/s/yt4qfxcc5yp3qmw/dataset.zip?dl=0\n",
    "# Unzip the dataset\n",
    "!unzip dataset.zip?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fa2CfJxVjJc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "categories = [\"Bat\", \"Boy\", \"Car\", \"Crocodile\", \"Girl\", \"House\", \"If\", \"Lion\", \"Monkey\", \"Tree\"]\n",
    "new_im_size = 128\n",
    "channels = 3\n",
    "\n",
    "train_data_dir = \"dataset/train\"\n",
    "test_data_dir = \"dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XhTyNeRVjJd"
   },
   "source": [
    "# 6.1 Dataset pre-processing\n",
    "The first thing that we need to do when we are dealing with a new dataset is to operate some pre-processing operations. Data preprocessing usually refers to the steps applied to make data more suitable for learning. \n",
    "In this section we are going to deal with:\n",
    "* 6.1.1 Dataset loading\n",
    "* 6.1.2 Normalization\n",
    "* 6.1.3 Standardization\n",
    "* 6.1.4 Splitting and label preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deYLU6wQVjJd"
   },
   "source": [
    "## 6.1.1 Dataset loading\n",
    "In this section we load the dataset generated in the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08lokc-cVjJd"
   },
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "def load_dataset(data_dir_path):\n",
    "\tX = []\n",
    "\tY = []\n",
    "\tfor i in range(len(categories)):\n",
    "\t\tcategory = categories[i]\n",
    "\t\tprint(\"Loading \" + category + \"..\")\n",
    "\n",
    "\t\timport glob\n",
    "\t\tonly_jpg = glob.glob(data_dir_path + \"/\" + category + \"/*.jpg\")\t\t\t\t# Getting all the .jpg images\n",
    "\t\tonly_png = glob.glob(data_dir_path + \"/\" + category + \"/*.png\")\t\t\t\t# Getting all the .png images\n",
    "\t\tonly_images = only_jpg + only_png\t\t\t\t\t\t\t\t\t\t\t# Merging all the images\n",
    "\n",
    "\t\tfor file_name in only_images:\t\t\t\t\t\t\t\t\t\t\t\t# For every image in the dataset\n",
    "\t\t\timage = Image.open(file_name).convert('RGB')\n",
    "\t\t\timage = image.resize((new_im_size, new_im_size))\t\t\t\t\t\t# Resize the image\n",
    "\t\t\tX.append(np.array(image, dtype=np.float32))\n",
    "\t\t\tY.append(i)\n",
    "\treturn X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBwwEcpMVjJd"
   },
   "outputs": [],
   "source": [
    "print(\"Loading training set..\")\n",
    "train_X, train_Y = load_dataset(train_data_dir)\t\t\t\t\t\t\t\t\t\t\t# Loading the training set\n",
    "\n",
    "# Creating the test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"Splitting training set to create test set..\")\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV_vaxfQVjJe"
   },
   "source": [
    "## 6.1.2 Standardization\n",
    "A common practice in data pre-processing is standardization.<br>\n",
    "The idea about standardization is to compute your dataset mean and standard deviation in order to subtract from every data point $x$ the dataset mean $\\mu$ and then divide by the standard deviation $\\sigma$.<br>\n",
    "That is to apply the following operation:<br>\n",
    "<img src=\"https://drive.google.com/uc?id=1rpuybw_fmI8XK38JQhWWxX2TOExBAV2V\" width=\"150px\"><br>\n",
    "The outcome of this operation is to obtain a distribution with mean equal to 0 and a standard deviation equal to 1.<br>\n",
    "By applying normalization to our data we are making the features more similar to each other and this usually makes the learning process easier.<br>\n",
    "To better understand that we can show an example of what happens after a standardization process is applied to a dataset:\n",
    "<img src=\"https://drive.google.com/uc?id=1wtqTW4hz8n8k7b7q0mUSzCc9X0npNUY2\" width=\"500px\" align=\"left\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWyx1B9hVjJf"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "def standardize_dataset(X):\n",
    "\timage_means = []\n",
    "\timage_stds = []\n",
    "\n",
    "\tfor image in X:\n",
    "\t\timage_means.append(np.mean(image))\t\t\t\t\t\t\t\t\t\t\t# Computing the image mean\n",
    "\t\timage_stds.append(np.std(image))\t\t\t\t\t\t\t\t\t\t\t# Computing the image standard deviation\n",
    "\n",
    "\tdataset_mean = np.mean(image_means)\t\t\t\t\t\t\t\t\t\t\t\t# Computing the dataset mean\n",
    "\tdataset_std = np.mean(image_stds)\t\t\t\t\t\t\t\t\t\t\t\t# Computing the dataset standard deviation\n",
    "\treturn dataset_mean, dataset_std\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0295n1kOVjJf"
   },
   "outputs": [],
   "source": [
    "dataset_mean, dataset_std = standardize_dataset(train_X)\n",
    "print(\"Standardizing training set..\")\n",
    "train_X = (train_X-dataset_mean)/dataset_std\t\t\t\t\t\t\t\t\t\t\t\t# Standardizing the training set\n",
    "print(\"Standardizing test set..\")\n",
    "test_X = (test_X-dataset_mean)/dataset_std\t\t\t\t\t\t\t\t\t\t\t\t# Standardizing the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF-q_fPSVjJe"
   },
   "source": [
    "## 6.1.3 Normalization\n",
    "Another common practice in training a Neural Network is to normalize the images by dividing each pixel value by the maximum value that we can have, i.e. 255.<br>\n",
    "The purpose of this is to obtain a mean close to 0.<br>\n",
    "Normalizing the data generally speeds up learning and leads to faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5R_RZfJdVjJe"
   },
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "print(\"Normalizing training set..\")\n",
    "train_X = np.asarray(train_X, dtype=np.float32) / 255\t\t\t\t\t\t\t\t\t\t# Normalizing training set\n",
    "print(\"Normalizing test set..\")\n",
    "test_X = np.asarray(test_X, dtype=np.float32) / 255\t\t\t\t\t\t\t\t\t\t\t# Normalizing test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGmDHeU-VjJf"
   },
   "source": [
    "## 6.1.4 Splitting and label preprocessing\n",
    "Now we just need to split our training set in orer to get the validation set and convert our labels to one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NWyc94bVjJg"
   },
   "outputs": [],
   "source": [
    "# Creating the validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"Splitting training set to create validation set..\")\n",
    "train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=13)\n",
    "\n",
    "# Converting labels to one-hot representation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "train_Y_one_hot = to_categorical(train_Y)\t\t\t\t\t\t# Converting training labels to one-hot representation\n",
    "valid_Y_one_hot = to_categorical(valid_Y)\t\t\t\t\t\t# Converting validation labels to one-hot representation\n",
    "test_Y_one_hot = to_categorical(test_Y)\t\t\t\t\t\t\t# Converting test labels to one-hot representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV88dGe_VjJg"
   },
   "source": [
    "# 6.2 Training a model from scratch\n",
    "Now that we have properly pre-processed our data, we are going to create a convolutional model in Keras. \n",
    "Usually a convolutional model is made by two subsequent part:\n",
    "* A convolutional part\n",
    "* A fully connected\n",
    "\n",
    "We can show an example of the general structure in the next picture:\n",
    "<img src=\"https://drive.google.com/uc?id=1duP8u9bs6ELNu4degUuYP4-YS1mBYn2O\" width=\"600px\"><br>\n",
    "\n",
    "Usually the convolutional part is made by some layers composed by\n",
    "* convolutional layer: performs a spatial convolution over images\n",
    "* pooling layer: used to reduce the output spatial dimension from $n$ to 1 by averaging the $n$ different value or considering the maximum between them \n",
    "* dropout layer: applied to a layer, consists of randomly \"dropping out\" (i.e. set to zero) a number of output features of the layer during training.\n",
    "\n",
    "The convolutional part produces its output and the fully connected part ties together the received information in order to solve the classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXSooP4bVjJg"
   },
   "outputs": [],
   "source": [
    "# Creating the model from scratch\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Network parameters\n",
    "batch_size = 16\t\t\t\t\t\t\t\t\t\t\t\t\t# Setting the batch size\n",
    "epochs = 10\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Setting the number of epochs\n",
    "num_classes = len(categories)\t\t\t\t\t\t\t\t\t# Getting the amount of classes\n",
    "\n",
    "scratch_model = Sequential()\t\n",
    "\n",
    "# Build here your keras model.\n",
    "# Try to use one or more convolutional layer, joint with pooling layer and dropout layer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model with the Adam optimizer\n",
    "scratch_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "# Visualize the model through the summary function\n",
    "scratch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFvLiE5dVjJh"
   },
   "outputs": [],
   "source": [
    "# Let's train the model!\n",
    "scratch_model_history = scratch_model.fit(train_X, train_Y_one_hot, batch_size=batch_size, shuffle=True, epochs=epochs, validation_data=(valid_X, valid_Y_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoZV8QifVjJh"
   },
   "outputs": [],
   "source": [
    "# Getting the results\n",
    "scratch_model_train_acc = scratch_model_history.history['accuracy']\n",
    "scratch_model_valid_acc = scratch_model_history.history['val_accuracy']\n",
    "scratch_model_train_loss = scratch_model_history.history['loss']\n",
    "scratch_model_valid_loss = scratch_model_history.history['val_loss']\n",
    "\n",
    "print(\"Test accuracy: \", accuracy_score(np.argmax(scratch_model.predict(test_X), axis=-1), test_Y))\t\t\t# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQD0moFYh1vR"
   },
   "outputs": [],
   "source": [
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-n6iYdgVjJi"
   },
   "source": [
    "**Is the obtained value coherent with what you expected?**<br>\n",
    "**What are the differences when using a different batch size? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Zi9UL_GVjJi"
   },
   "source": [
    "# 6.3 Data Augmentation\n",
    "Before even starting to load the dataset we should ask ourself whether the available amount of data is sufficient to our purposes.<br>\n",
    "When the answer is negative we could need to do \"data augmentation\".<br>\n",
    "Doing data augmentation means to increase the number of available data points. In terms of images, it may mean that increasing the number of images in the dataset. A common way to do this is to generate new images by applying a linear transformation to the original images in the dataset.<br>\n",
    "The most common linear transformations are the following:<br>\n",
    "* Rotation\n",
    "* Shifting\n",
    "* Blurring\n",
    "* Change lighting conditions\n",
    "\n",
    "In the picture below we show an example of augmentation:<br>\n",
    "<img src=\"https://drive.google.com/uc?id=1B74snda_oJKkhVzxch9Ov8Y1XL63U3w5\" width=\"600px\" align=\"left\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBkNd92ZVjJj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "  rotation_range=5,\n",
    "  width_shift_range=0.1,\n",
    "  height_shift_range=0.1,\n",
    "  fill_mode=\"nearest\",\n",
    ")\n",
    "\n",
    "flow = datagen.flow(train_X, train_Y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MUxmyFgVjJk"
   },
   "source": [
    "Now try to build a new model dealing with the augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dexaO6glVjJk"
   },
   "outputs": [],
   "source": [
    "# Build here your keras model dealing with the augmented dataset\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q30Gq29PVjJk"
   },
   "source": [
    "**What is the performance obtained on this new augmented dataset?**<br>\n",
    "**How can you explain the obtained result?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vTxXtoiVjJk"
   },
   "source": [
    "# 6.4 Using a pre-trained model\n",
    "A common alternative to train a model from scratch consists in using a pre-trained model.<br>\n",
    "The idea is to replace the convolutional part with a highly optimized convolutional part engineered and trained previously by someone else.<br>\n",
    "Usually the models that we can use through keras.applications have been trained over the image net dataset. <br>\n",
    "Today we are going to use the Xception Net model. Its architecture it is shown below:\n",
    "<img src=\"https://drive.google.com/uc?id=1eKivBCSKnWKyBxmGe5s64oOyhzhuCaqU\" width=\"600px\"><br>\n",
    "After the convolutional part replacement we still need to set up a fully connected part.<br>\n",
    "**Why in this lab we cannot use the fully connected part of Xception Net?<br>\n",
    "What should we do to use it?<br>\n",
    "And more in general in which situations we can do that?**\n",
    "\n",
    "Moreover, using a pre-trained network is not always the best choice<br>\n",
    "**Can you guess in which situations could be useful to use a pre-trained model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDEXDdJMVjJk"
   },
   "outputs": [],
   "source": [
    "# Creating the model based over the pretrained Xception network\n",
    "from tensorflow.keras import applications\n",
    "Xception_model = applications.Xception(weights = \"imagenet\", include_top=False, input_shape = (new_im_size, new_im_size, channels))\n",
    "\n",
    "# Producing the feature\n",
    "train_X_feature = Xception_model.predict(train_X)\t\t\t\t\t# Producing the train feature\n",
    "valid_X_feature = Xception_model.predict(valid_X)\t\t\t\t\t# Producing the test feature\n",
    "\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# Creating a simple model that will classify the extracted features from the Xception network\n",
    "pretrained_model = models.Sequential()\n",
    "pretrained_model.add(layers.Flatten())\n",
    "pretrained_model.add(layers.Dense(64, activation='relu'))\n",
    "pretrained_model.add(layers.Dropout(0.3))\n",
    "pretrained_model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "pretrained_model.compile(optimizer=optimizers.RMSprop(lr=2e-4),loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2SR16fyVjJk"
   },
   "outputs": [],
   "source": [
    "# Visualize the model through the summary function\n",
    "scratch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAeeI4iiVjJl"
   },
   "outputs": [],
   "source": [
    "# Let's train the model!\n",
    "pretrained_model_history = pretrained_model.fit(train_X_feature, train_Y_one_hot, epochs=epochs, batch_size=batch_size, validation_data=(valid_X_feature, valid_Y_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prOfnnUrVjJl"
   },
   "outputs": [],
   "source": [
    "# Getting the results\n",
    "pretrained_model_train_acc = pretrained_model_history.history['acc']\n",
    "pretrained_model_valid_acc = pretrained_model_history.history['val_acc']\n",
    "pretrained_model_train_loss = pretrained_model_history.history['loss']\n",
    "pretrained_model_valid_loss = pretrained_model_history.history['val_loss']\n",
    "\n",
    "test_X_feature = Xception_model.predict(test_X)\t\t\t\t\t\t# Producing the test feature\n",
    "print(\"Test accuracy: \", accuracy_score(np.argmax(scratch_model.predict(test_X), axis=-1), test_Y))\t\t\t# Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjXsWgr7VjJl"
   },
   "source": [
    "# 6.5 Comparing the models\n",
    "Now that we trained both the \"from scratch\" and the \"pre-trained\" models, we are going to compare the obtained results obtained during the training. We are going to consider accuracy and loss.<br>\n",
    "**What can you expect from these plots?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUGbtQrzVjJl"
   },
   "outputs": [],
   "source": [
    "# Create here the plots to compare the \"from scratch\" model and the \"pretrained\" model\n",
    "# Try to produce a comparison plot about the accuracies (train and validation) and another plot for the losses\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swjizU_7VjJl"
   },
   "source": [
    "**What information can you get from these plots?**<br>\n",
    "**Are they showing what you expected?**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
